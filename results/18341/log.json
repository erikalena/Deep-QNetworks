{
    "configuration": {
        "current_time": "20230717-162815",
        "description": "Deep Q-Network Snake with gym and class agent, done after snake eats itself",
        "device": "cuda",
        "batch_size": 32,
        "env_size_x": 20,
        "env_size_y": 20,
        "num_envs": 1,
        "max_steps_per_episode": 10000,
        "max_num_episodes": 20000,
        "deque_size": 100,
        "epsilon_max": 1.0,
        "epsilon_min": 0.1,
        "learning_rate": 0.01,
        "done_on_collision": true,
        "update_after_actions": 4,
        "update_target_network": 10000,
        "epsilon_random_frames": 50000,
        "epsilon_greedy_frames": 100000.0,
        "buffer_size": 100000,
        "output_filename": "log.json",
        "output_logdir": "./results/18341",
        "output_checkpoint_dir": "./checkpoint/18341",
        "save_step": 100,
        "logging_level": 10,
        "reward": {
            "eat": 100,
            "collision": -100,
            "step": 0
        }
    },
    "episode_99": {
        "training_error": "0.22821502764749524",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9900000000000011"
    },
    "episode_199": {
        "training_error": "0.22084118070368797",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9800000000000022"
    },
    "episode_299": {
        "training_error": "0.2157770922314571",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9700000000000033"
    },
    "episode_399": {
        "training_error": "0.20912340341955896",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9600000000000044"
    },
    "episode_499": {
        "training_error": "0.19907775970852376",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9500000000000055"
    },
    "episode_599": {
        "training_error": "0.19388541638207132",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9400000000000066"
    },
    "episode_699": {
        "training_error": "0.19138544862438522",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9300000000000077"
    },
    "episode_799": {
        "training_error": "0.18931702437093115",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9200000000000088"
    },
    "episode_899": {
        "training_error": "0.18764632176992263",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.9100000000000099"
    },
    "episode_999": {
        "training_error": "0.18478195849598528",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.900000000000011"
    },
    "episode_1099": {
        "training_error": "0.18336670537508365",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8900000000000121"
    },
    "episode_1199": {
        "training_error": "0.18170292521337797",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8800000000000132"
    },
    "episode_1299": {
        "training_error": "0.18186169315442516",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8700000000000143"
    },
    "episode_1399": {
        "training_error": "0.18032439355677768",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8600000000000154"
    },
    "episode_1499": {
        "training_error": "0.17959082851411146",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8500000000000165"
    },
    "episode_1599": {
        "training_error": "0.1799661318197575",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8400000000000176"
    },
    "episode_1699": {
        "training_error": "0.18037752342498825",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8300000000000187"
    },
    "episode_1799": {
        "training_error": "0.17995669881443688",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8200000000000198"
    },
    "episode_1899": {
        "training_error": "0.18042153334202404",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.8100000000000209"
    },
    "episode_1999": {
        "training_error": "0.18044727789885184",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.800000000000022"
    },
    "episode_2099": {
        "training_error": "0.18067380975654646",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7900000000000231"
    },
    "episode_2199": {
        "training_error": "0.18127474670344276",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7800000000000242"
    },
    "episode_2299": {
        "training_error": "0.18182972469323203",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7700000000000253"
    },
    "episode_2399": {
        "training_error": "0.18217804626156947",
        "mean_eaten": 1.04,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7600000000000264"
    },
    "episode_2499": {
        "training_error": "0.18239959323179397",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7500000000000275"
    },
    "episode_2599": {
        "training_error": "0.18273122199568165",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7400000000000286"
    },
    "episode_2699": {
        "training_error": "0.18308517896962062",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7300000000000297"
    },
    "episode_2799": {
        "training_error": "0.18381920167016205",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7200000000000308"
    },
    "episode_2899": {
        "training_error": "0.18463586009209956",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.7100000000000319"
    },
    "episode_2999": {
        "training_error": "0.18534944432717249",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.700000000000033"
    },
    "episode_3099": {
        "training_error": "0.1855974672499612",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6900000000000341"
    },
    "episode_3199": {
        "training_error": "0.18592512349035037",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6800000000000352"
    },
    "episode_3299": {
        "training_error": "0.1862452433401914",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6700000000000363"
    },
    "episode_3399": {
        "training_error": "0.18671676429210146",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6600000000000374"
    },
    "episode_3499": {
        "training_error": "0.18769221589096605",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6500000000000385"
    },
    "episode_3599": {
        "training_error": "0.18854790273629754",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6400000000000396"
    },
    "episode_3699": {
        "training_error": "0.18915523917557445",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6300000000000407"
    },
    "episode_3799": {
        "training_error": "0.18972126425463337",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.6200000000000419"
    },
    "episode_3899": {
        "training_error": "0.1902763825582461",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.610000000000043"
    },
    "episode_3999": {
        "training_error": "0.19050593027982107",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.600000000000044"
    },
    "episode_4099": {
        "training_error": "0.19090165336939752",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5900000000000452"
    },
    "episode_4199": {
        "training_error": "0.19114213139800706",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5800000000000463"
    },
    "episode_4299": {
        "training_error": "0.19162326213088446",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5700000000000474"
    },
    "episode_4399": {
        "training_error": "0.19234463400247032",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5600000000000485"
    },
    "episode_4499": {
        "training_error": "0.19305241783516128",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5500000000000496"
    },
    "episode_4599": {
        "training_error": "0.19310780998026078",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5400000000000507"
    },
    "episode_4699": {
        "training_error": "0.1937016212885298",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5300000000000518"
    },
    "episode_4799": {
        "training_error": "0.19418829154747658",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5200000000000529"
    },
    "episode_4899": {
        "training_error": "0.19487841326317507",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.510000000000054"
    },
    "episode_4999": {
        "training_error": "0.1957607935211919",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.5000000000000551"
    },
    "episode_5099": {
        "training_error": "0.1963622539296757",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.49000000000005617"
    },
    "episode_5199": {
        "training_error": "0.19666444474209915",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.48000000000005727"
    },
    "episode_5299": {
        "training_error": "0.19702717153357097",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.47000000000005837"
    },
    "episode_5399": {
        "training_error": "0.197424983806575",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4600000000000595"
    },
    "episode_5499": {
        "training_error": "0.1978196274145386",
        "mean_eaten": 1.02,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4500000000000606"
    },
    "episode_5599": {
        "training_error": "0.19764550847712092",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4400000000000617"
    },
    "episode_5699": {
        "training_error": "0.1977108018532398",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4300000000000628"
    },
    "episode_5799": {
        "training_error": "0.1981214470875454",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4200000000000639"
    },
    "episode_5899": {
        "training_error": "0.19871493914514",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.410000000000065"
    },
    "episode_5999": {
        "training_error": "0.1991564634293277",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.4000000000000661"
    },
    "episode_6099": {
        "training_error": "0.19915825620365407",
        "mean_eaten": 1.02,
        "mean_reward": 0.1447178002894356,
        "eatens": 2,
        "epsilon": "0.3900000000000672"
    },
    "episode_6199": {
        "training_error": "0.19923428194634096",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3800000000000683"
    },
    "episode_6299": {
        "training_error": "0.19927536006908786",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3700000000000694"
    },
    "episode_6399": {
        "training_error": "0.19929009563567837",
        "mean_eaten": 1.04,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3600000000000705"
    },
    "episode_6499": {
        "training_error": "0.19960396859276172",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3500000000000716"
    },
    "episode_6599": {
        "training_error": "0.19966031369259166",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3400000000000727"
    },
    "episode_6699": {
        "training_error": "0.19973333457803338",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3300000000000738"
    },
    "episode_6799": {
        "training_error": "0.19984256953650228",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3200000000000749"
    },
    "episode_6899": {
        "training_error": "0.19967323439236911",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.310000000000076"
    },
    "episode_6999": {
        "training_error": "0.1995088098655707",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.3000000000000771"
    },
    "episode_7099": {
        "training_error": "0.19975822102311683",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2900000000000782"
    },
    "episode_7199": {
        "training_error": "0.20004289999039931",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2800000000000793"
    },
    "episode_7299": {
        "training_error": "0.20033853244705757",
        "mean_eaten": 1.0,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2700000000000804"
    },
    "episode_7399": {
        "training_error": "0.2004740831773864",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2600000000000815"
    },
    "episode_7499": {
        "training_error": "0.2001077839703698",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2500000000000826"
    },
    "episode_7599": {
        "training_error": "0.19991948015195068",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2400000000000837"
    },
    "episode_7699": {
        "training_error": "0.19973029413768145",
        "mean_eaten": 1.04,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2300000000000848"
    },
    "episode_7799": {
        "training_error": "0.1996254448639015",
        "mean_eaten": 1.03,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2200000000000859"
    },
    "episode_7899": {
        "training_error": "0.19980205548111718",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.210000000000087"
    },
    "episode_7999": {
        "training_error": "0.1996640299467503",
        "mean_eaten": 1.01,
        "mean_reward": 0.0,
        "eatens": 1,
        "epsilon": "0.2000000000000881"
    }
}